{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "NextWordPrediction_LSTM_optimized-GPU.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "e85Gvm42avDD",
        "colab_type": "code",
        "outputId": "d92e5e7d-9892-4aae-9286-00c788b9511a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 79
        }
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "import tensorflow as tf\n",
        "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Num GPUs Available:  1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uDfwWDsAavDG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import gensim\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T0x_8emObooJ",
        "colab_type": "code",
        "outputId": "45d09eae-98ad-49c2-cd4a-10416df807a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UspqjNmVdi2O",
        "colab_type": "code",
        "outputId": "ece3d7aa-1191-4ca1-f72c-50d39fc4f0fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "!wget -P /root/input/ -c \"https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\""
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-12-08 01:20:43--  https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.216.96.5\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.216.96.5|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1647046227 (1.5G) [application/x-gzip]\n",
            "Saving to: ‘/root/input/GoogleNews-vectors-negative300.bin.gz’\n",
            "\n",
            "GoogleNews-vectors- 100%[===================>]   1.53G  22.7MB/s    in 43s     \n",
            "\n",
            "2019-12-08 01:21:27 (36.2 MB/s) - ‘/root/input/GoogleNews-vectors-negative300.bin.gz’ saved [1647046227/1647046227]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZmLjXK6javDT",
        "colab_type": "code",
        "outputId": "1c8b110b-8658-42cc-f0e7-01b305f55850",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "word2vec = gensim.models.KeyedVectors.load_word2vec_format('/root/input/GoogleNews-vectors-negative300.bin.gz', binary=True)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:402: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1RaJT-vNavDW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qTIMEzKlavDZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab = set()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQbE7NMqavDn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras import backend as K\n",
        "#from keras import backend as K\n",
        "def perplexity(y_true, y_pred):\n",
        "    cross_entropy = K.categorical_crossentropy(y_true, y_pred)\n",
        "    return K.pow(2.0, cross_entropy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A0FRC5IzavDp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "emailTokens = pd.read_pickle('drive/My Drive/Next Word Prediction/emailTokens')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bl0JtQawavDq",
        "colab_type": "code",
        "outputId": "5e49f580-63a0-4eb8-d553-d7e1f8237dbd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "emailTokens.head()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0                            [here, is, our, forecast]\n",
              "1    [traveling, have, business, meeting, takes, th...\n",
              "2                          [test, successful, way, go]\n",
              "3    [randy, can, you, send, me, schedule, the, sal...\n",
              "4                      [lets, shoot, for, tuesday, at]\n",
              "Name: message_tokens, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2vdiIaFavDs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#emailsdf['message_tokens'].head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jZXASh_RavDt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import ast"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "okih0LO1avDv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# with open('vocab.txt','w') as f:\n",
        "#     f.write(str(vocab))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kV-83P7HavDw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('drive/My Drive/Next Word Prediction/vocab.txt','r') as f:\n",
        "    vocab = ast.literal_eval(f.read())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hwE4NIFpavDy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Convert vocab set to a dictionary\n",
        "word_map = dict()\n",
        "inverse_word_map = dict()\n",
        "i = 1\n",
        "for x in vocab:\n",
        "    word_map[x] = i\n",
        "    inverse_word_map[i] = x\n",
        "    i+=1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KNQTQL18avD1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word_map[''] = 0\n",
        "inverse_word_map[0] = ''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbhSrTRNavD4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab.add('')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xa7E96PoavD5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seq_len = 5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y_2tIoE4avD6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import copy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cHajiTVdavEA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tqdm import tqdm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6bMDspbdavEC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def makeSequences(test):\n",
        "    sequences = list()\n",
        "    number_sequence = list()\n",
        "    w2v_sequence = list()\n",
        "\n",
        "    for sentence in test:\n",
        "        for i in range(seq_len):\n",
        "            sentence.insert(0,'')\n",
        "        for i in range(seq_len,len(sentence)):\n",
        "            sequence = sentence[i-seq_len:i+1]\n",
        "            sequences.append(sequence)\n",
        "            seq_i = list()\n",
        "            seq_w2v = list()\n",
        "            for word in sequence:\n",
        "                seq_i.append(word_map[word])\n",
        "                if(word == \"\"):\n",
        "                    seq_w2v.append(np.zeros(300))\n",
        "                else:\n",
        "                    seq_w2v.append(word2vec[word])\n",
        "            number_sequence.append(seq_i)\n",
        "            w2v_sequence.append(seq_w2v)\n",
        "    return (sequences,number_sequence,w2v_sequence)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YU4_TP1gavEE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def makeSequencestest(test):\n",
        "    sequences = list()\n",
        "    number_sequence = list()\n",
        "    w2v_sequence = list()\n",
        "    sentences = list()\n",
        "    for sentence in test:\n",
        "        for i in range(seq_len):\n",
        "            sentence.insert(0,'')\n",
        "        for i in range(seq_len,len(sentence)):\n",
        "            sequence = sentence[i-seq_len:i+1]\n",
        "            sequences.append(sequence)\n",
        "            seq_i = list()\n",
        "            seq_w2v = list()\n",
        "            sen = list()\n",
        "            for word in sequence:\n",
        "                seq_i.append(word_map[word])\n",
        "                if(word == \"\"):\n",
        "                    seq_w2v.append(np.zeros(300))\n",
        "                else:\n",
        "                    seq_w2v.append(word2vec[word])\n",
        "                sen.append(word)\n",
        "            number_sequence.append(seq_i)\n",
        "            w2v_sequence.append(seq_w2v)\n",
        "            sentences.append(sen)\n",
        "    return (sequences,number_sequence,w2v_sequence,sentences)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sIDYZOJjavEF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Removing long emails\n",
        "emailTokens = [s for s in emailTokens if len(s) <= 50 and len(s)>1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Q6sEjiWavEG",
        "colab_type": "code",
        "outputId": "283f98e8-1fdc-4517-a7aa-34ec7459899a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(emailTokens)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "164559"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MwfiELkJavEI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Train-Test Split 50-25-25\n",
        "train = emailTokens[0:int(0.5*len(emailTokens))]\n",
        "val = emailTokens[int(0.5*len(emailTokens)):int(0.75*len(emailTokens))]\n",
        "test = emailTokens[int(0.75*len(emailTokens)):]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xgK7GH88avEL",
        "colab_type": "code",
        "outputId": "0ec11b46-f7d8-4d99-8bea-9d66f8f8c550",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(train)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "82279"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sgoPmYNWavEN",
        "colab_type": "code",
        "outputId": "c6c4698d-13de-440c-c139-1dc8e5fca73c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(val)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "41140"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pN23o5WiavEQ",
        "colab_type": "code",
        "outputId": "bc4e8e6a-722c-431f-a172-36377582a5a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(test)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "41140"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XRumlwgNavES",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from numpy import array\n",
        "#from keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "#from keras.utils import to_categorical\n",
        "#from keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "#from keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "#from keras.layers import Dense,CuDNNLSTM\n",
        "#from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.compat.v1.keras.layers import CuDNNLSTM\n",
        "#from keras.layers import Embedding"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ZwJbbgkavET",
        "colab_type": "code",
        "outputId": "36975e65-ef6c-447a-daf3-ee6f44ca2354",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(vocab)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "77826"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ioWcbSdwavEX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sequence_x_y(data):\n",
        "    (sequences,number_sequence,w2v_sequence) = makeSequences(data)\n",
        "    w2v_X = list()\n",
        "    #w2v_y = list()\n",
        "    y = list()\n",
        "    for i in range(len(w2v_sequence)):\n",
        "        w2v_X.append(w2v_sequence[i][:-1])\n",
        "        #w2v_y.append(w2v_sequence[i][-1])\n",
        "        y.append(to_categorical(number_sequence[i][-1], num_classes=vocab_size))\n",
        "    return ([np.array(w2v_X).reshape((-1, seq_len, 300))],[np.array(y)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Ve5CuM4avEZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sequence_x_ytest(data):\n",
        "    (sequences,number_sequence,w2v_sequence,sentences) = makeSequencestest(data)\n",
        "    w2v_X = list()\n",
        "    #w2v_y = list()\n",
        "    y = list()\n",
        "    for i in range(len(w2v_sequence)):\n",
        "        w2v_X.append(w2v_sequence[i][:-1])\n",
        "        #w2v_y.append(w2v_sequence[i][-1])\n",
        "        y.append(to_categorical(number_sequence[i][-1], num_classes=vocab_size))\n",
        "    return ([np.array(w2v_X).reshape((-1, seq_len, 300))],[np.array(y)],[sentences])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zib2Je0WavEh",
        "colab_type": "code",
        "outputId": "1fd6160c-8be8-4927-ace9-71367edf82f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "vocab_size = len(vocab)\n",
        "vocab_size"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "77826"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K6fGJ8E5avEt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 128\n",
        "val_batch_size = 16"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v08Yrn2mavEx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.utils import Sequence\n",
        "#from keras.utils import Sequence"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sRfB0cbDavEy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class KerasBatchGenerator(Sequence):\n",
        "\n",
        "    def __init__(self, data,vocab_size,batch_size):\n",
        "        self.data = data\n",
        "        self.vocab_size = vocab_size\n",
        "        self.batch_size = batch_size\n",
        "        self.current_idx = 0\n",
        "        self.batchNum=1\n",
        "        self.w2v_X = None\n",
        "        self.y = None\n",
        "        self.content = None\n",
        "    def generate(self):\n",
        "        while True:\n",
        "            #gc.collect()\n",
        "            #if(self.batchNum==1):\n",
        "                #print(\"1st Batch\")\n",
        "            self.w2v_X = None\n",
        "            self.y = None\n",
        "            self.content = None\n",
        "            self.batchNum+=1\n",
        "            if(self.current_idx+self.batch_size >= len(self.data)):\n",
        "                #print(\"Data from\", str(self.current_idx),\"till end\")\n",
        "                self.content = copy.deepcopy(self.data[self.current_idx:])\n",
        "                self.batchNum = 1\n",
        "                self.current_idx = 0\n",
        "                gc.collect()\n",
        "                #print(\"Epoch Completed\",str(self.batchNum))\n",
        "            else:\n",
        "                #print(\"Data from\", str(self.current_idx),\"to\",str(self.current_idx+self.batch_size))\n",
        "                self.content = copy.deepcopy(self.data[self.current_idx:self.current_idx+self.batch_size])\n",
        "                self.current_idx+=self.batch_size\n",
        "            \n",
        "            (self.w2v_X,self.y) = sequence_x_y(self.content)\n",
        "            yield (self.w2v_X.pop(), self.y.pop())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hrJxiZXnruAg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Used for evaluation\n",
        "class KerastestBatchGenerator(Sequence):\n",
        "\n",
        "    def __init__(self, data,vocab_size,batch_size):\n",
        "        self.data = data\n",
        "        self.vocab_size = vocab_size\n",
        "        self.batch_size = batch_size\n",
        "        self.current_idx = 0\n",
        "        self.batchNum=1\n",
        "        self.w2v_X = None\n",
        "        self.y = None\n",
        "        self.content = None\n",
        "        self.sentences = None\n",
        "    def generate(self):\n",
        "        while True:\n",
        "            #gc.collect()\n",
        "            #if(self.batchNum==1):\n",
        "                #print(\"1st Batch\")\n",
        "            self.w2v_X = None\n",
        "            self.y = None\n",
        "            self.content = None\n",
        "            self.sentences = None\n",
        "            self.batchNum+=1\n",
        "            if(self.current_idx+self.batch_size >= len(self.data)):\n",
        "                #print(\"Data from\", str(self.current_idx),\"till end\")\n",
        "                self.content = copy.deepcopy(self.data[self.current_idx:])\n",
        "                self.batchNum = 1\n",
        "                self.current_idx = 0\n",
        "                gc.collect()\n",
        "                #print(\"Epoch Completed\",str(self.batchNum))\n",
        "            else:\n",
        "                #print(\"Data from\", str(self.current_idx),\"to\",str(self.current_idx+self.batch_size))\n",
        "                self.content = copy.deepcopy(self.data[self.current_idx:self.current_idx+self.batch_size])\n",
        "                self.current_idx+=self.batch_size\n",
        "            \n",
        "            (self.w2v_X,self.y,self.sentences) = sequence_x_ytest(self.content)\n",
        "            yield (self.w2v_X.pop(), self.y.pop(),self.sentences.pop())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yYALwOiRavE0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_generator = KerasBatchGenerator(train,vocab_size,batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1vOTxISmavE1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Using only a part of the data for validation\n",
        "val_generator = KerasBatchGenerator(val[0:100],vocab_size,val_batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "skGkjX_savE3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_epochs=40"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6xxFjRnRavE4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "# from tensorflow.keras.layers import LSTM, Dense"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "anXuOTruavE5",
        "colab_type": "code",
        "outputId": "d1552b32-92af-43f8-a920-dd3a0f7c4ad3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "#Define the model\n",
        "model = Sequential()\n",
        "model.add(CuDNNLSTM(50, input_shape=(seq_len, 300)))\n",
        "model.add(Dense(vocab_size, activation='softmax'))"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lavbkZxQavE6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy',perplexity])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WboirIEEavE9",
        "colab_type": "code",
        "outputId": "262a5443-ac16-4fe6-cce8-dc6e570054ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "cu_dnnlstm (CuDNNLSTM)       (None, 50)                70400     \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 77826)             3969126   \n",
            "=================================================================\n",
            "Total params: 4,039,526\n",
            "Trainable params: 4,039,526\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WLP77UNYavE_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math\n",
        "import tqdm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "NLycSsdjavFA",
        "colab_type": "code",
        "outputId": "552557c8-b343-4e32-fe09-e95ba8c57f7c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        }
      },
      "source": [
        "#Train the model\n",
        "hist = model.fit_generator(train_generator.generate(), math.ceil(len(train)/(batch_size)), epochs = num_epochs,\n",
        "                              validation_data=val_generator.generate(),\n",
        "                              validation_steps=math.ceil(len(val[0:100])/(val_batch_size)),verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "642/643 [============================>.] - ETA: 0s - loss: 7.3260 - acc: 0.0379 - perplexity: 935.1507Epoch 1/10\n",
            "643/643 [==============================] - 562s 873ms/step - loss: 7.3257 - acc: 0.0379 - perplexity: 935.7480 - val_loss: 7.2462 - val_acc: 0.0497 - val_perplexity: 1203.6311\n",
            "Epoch 2/10\n",
            "642/643 [============================>.] - ETA: 0s - loss: 6.8346 - acc: 0.0469 - perplexity: 499.6470Epoch 1/10\n",
            "643/643 [==============================] - 544s 846ms/step - loss: 6.8347 - acc: 0.0469 - perplexity: 500.0984 - val_loss: 6.9720 - val_acc: 0.0754 - val_perplexity: 791.7641\n",
            "Epoch 3/10\n",
            "642/643 [============================>.] - ETA: 0s - loss: 6.5551 - acc: 0.0706 - perplexity: 450.7425Epoch 1/10\n",
            "643/643 [==============================] - 534s 830ms/step - loss: 6.5552 - acc: 0.0706 - perplexity: 451.0654 - val_loss: 6.7170 - val_acc: 0.0842 - val_perplexity: 680.5971\n",
            "Epoch 4/10\n",
            "642/643 [============================>.] - ETA: 0s - loss: 6.2853 - acc: 0.0974 - perplexity: 400.8062Epoch 1/10\n",
            "643/643 [==============================] - 531s 826ms/step - loss: 6.2855 - acc: 0.0974 - perplexity: 401.0895 - val_loss: 6.5202 - val_acc: 0.1030 - val_perplexity: 612.7736\n",
            "Epoch 5/10\n",
            "642/643 [============================>.] - ETA: 0s - loss: 6.0533 - acc: 0.1159 - perplexity: 357.2072Epoch 1/10\n",
            "643/643 [==============================] - 526s 818ms/step - loss: 6.0536 - acc: 0.1159 - perplexity: 357.4807 - val_loss: 6.3485 - val_acc: 0.1094 - val_perplexity: 568.6833\n",
            "Epoch 6/10\n",
            "642/643 [============================>.] - ETA: 0s - loss: 5.8609 - acc: 0.1263 - perplexity: 324.8671Epoch 1/10\n",
            "643/643 [==============================] - 522s 811ms/step - loss: 5.8613 - acc: 0.1263 - perplexity: 325.1220 - val_loss: 6.2200 - val_acc: 0.1166 - val_perplexity: 529.1506\n",
            "Epoch 7/10\n",
            "642/643 [============================>.] - ETA: 0s - loss: 5.6963 - acc: 0.1406 - perplexity: 296.5656Epoch 1/10\n",
            "643/643 [==============================] - 517s 805ms/step - loss: 5.6968 - acc: 0.1406 - perplexity: 296.8011 - val_loss: 6.1108 - val_acc: 0.1234 - val_perplexity: 492.5117\n",
            "Epoch 8/10\n",
            "642/643 [============================>.] - ETA: 0s - loss: 5.5478 - acc: 0.1567 - perplexity: 271.9103Epoch 1/10\n",
            "643/643 [==============================] - 525s 817ms/step - loss: 5.5484 - acc: 0.1567 - perplexity: 272.1276 - val_loss: 6.0154 - val_acc: 0.1375 - val_perplexity: 460.3003\n",
            "Epoch 9/10\n",
            "642/643 [============================>.] - ETA: 0s - loss: 5.4168 - acc: 0.1733 - perplexity: 252.0908Epoch 1/10\n",
            "643/643 [==============================] - 537s 835ms/step - loss: 5.4175 - acc: 0.1733 - perplexity: 252.2926 - val_loss: 5.9368 - val_acc: 0.1443 - val_perplexity: 431.2383\n",
            "Epoch 10/10\n",
            "642/643 [============================>.] - ETA: 0s - loss: 5.3002 - acc: 0.1865 - perplexity: 236.3969Epoch 1/10\n",
            "643/643 [==============================] - 538s 837ms/step - loss: 5.3010 - acc: 0.1864 - perplexity: 236.5865 - val_loss: 5.8694 - val_acc: 0.1503 - val_perplexity: 405.6649\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "36q8wcczavFE",
        "colab_type": "code",
        "outputId": "127ced64-abae-4d80-c021-21c7845d21a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "hist.history"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'acc': [0.038161583,\n",
              "  0.047983527,\n",
              "  0.07284822,\n",
              "  0.09809936,\n",
              "  0.11452181,\n",
              "  0.12683383,\n",
              "  0.14405634,\n",
              "  0.1632115,\n",
              "  0.17599446,\n",
              "  0.18941191,\n",
              "  0.19891116,\n",
              "  0.20820485,\n",
              "  0.21667576,\n",
              "  0.22238381,\n",
              "  0.22763723,\n",
              "  0.23257342,\n",
              "  0.23723483,\n",
              "  0.2412578,\n",
              "  0.24485579,\n",
              "  0.24800804,\n",
              "  0.251143,\n",
              "  0.25409165,\n",
              "  0.25645918,\n",
              "  0.25870958,\n",
              "  0.26101187,\n",
              "  0.26320052,\n",
              "  0.2653101,\n",
              "  0.2671879,\n",
              "  0.26912946,\n",
              "  0.2708348,\n",
              "  0.27242157,\n",
              "  0.27390453,\n",
              "  0.2753406,\n",
              "  0.27680427,\n",
              "  0.27802733,\n",
              "  0.27929732,\n",
              "  0.2806093,\n",
              "  0.28181162,\n",
              "  0.28311175,\n",
              "  0.28420186],\n",
              " 'loss': [7.316876920573543,\n",
              "  6.829084748976582,\n",
              "  6.5455171526033515,\n",
              "  6.2782118812676915,\n",
              "  6.051699852368849,\n",
              "  5.856082385629648,\n",
              "  5.673014378459329,\n",
              "  5.5104227564797785,\n",
              "  5.37353292849194,\n",
              "  5.258293249985147,\n",
              "  5.159916819194751,\n",
              "  5.074276493564709,\n",
              "  4.999546957992154,\n",
              "  4.933962097996374,\n",
              "  4.875933995936033,\n",
              "  4.824516829723745,\n",
              "  4.778735741880142,\n",
              "  4.7376851728674145,\n",
              "  4.700779586611394,\n",
              "  4.667264661332943,\n",
              "  4.636728354446207,\n",
              "  4.608747438965592,\n",
              "  4.582992416452707,\n",
              "  4.559260959782075,\n",
              "  4.537215898223458,\n",
              "  4.51670165671297,\n",
              "  4.497541865169486,\n",
              "  4.479569278858079,\n",
              "  4.462658202567776,\n",
              "  4.4467557597698715,\n",
              "  4.431734074233373,\n",
              "  4.417543852150973,\n",
              "  4.4040877787998784,\n",
              "  4.391332101572793,\n",
              "  4.379185639924792,\n",
              "  4.367639664187518,\n",
              "  4.356581641578387,\n",
              "  4.3459980809896726,\n",
              "  4.335887419959156,\n",
              "  4.326187695043071],\n",
              " 'perplexity': [928.4225,\n",
              "  501.0731,\n",
              "  449.8583,\n",
              "  399.73337,\n",
              "  357.51486,\n",
              "  325.23807,\n",
              "  294.24292,\n",
              "  267.9713,\n",
              "  247.67715,\n",
              "  232.35909,\n",
              "  220.63533,\n",
              "  211.77441,\n",
              "  205.26656,\n",
              "  200.89413,\n",
              "  198.32951,\n",
              "  197.26826,\n",
              "  197.49203,\n",
              "  198.93027,\n",
              "  201.34578,\n",
              "  204.72154,\n",
              "  209.03198,\n",
              "  214.18858,\n",
              "  220.17006,\n",
              "  226.63478,\n",
              "  233.39288,\n",
              "  240.24922,\n",
              "  246.97507,\n",
              "  253.2452,\n",
              "  258.96964,\n",
              "  263.73022,\n",
              "  268.37354,\n",
              "  272.20184,\n",
              "  276.16928,\n",
              "  279.55118,\n",
              "  283.81137,\n",
              "  286.74353,\n",
              "  290.5872,\n",
              "  293.8912,\n",
              "  297.23984,\n",
              "  300.12457],\n",
              " 'val_acc': [0.0496994,\n",
              "  0.07735471,\n",
              "  0.08416834,\n",
              "  0.099799596,\n",
              "  0.10701403,\n",
              "  0.111422844,\n",
              "  0.12024048,\n",
              "  0.13186373,\n",
              "  0.13627255,\n",
              "  0.14629258,\n",
              "  0.15150301,\n",
              "  0.15631263,\n",
              "  0.16072144,\n",
              "  0.16312625,\n",
              "  0.16873747,\n",
              "  0.17114228,\n",
              "  0.17354709,\n",
              "  0.17635271,\n",
              "  0.1747495,\n",
              "  0.17635271,\n",
              "  0.17755511,\n",
              "  0.1783567,\n",
              "  0.17915832,\n",
              "  0.17955911,\n",
              "  0.18116233,\n",
              "  0.18236473,\n",
              "  0.18196392,\n",
              "  0.18396793,\n",
              "  0.18597195,\n",
              "  0.18917836,\n",
              "  0.19238476,\n",
              "  0.19398798,\n",
              "  0.19358717,\n",
              "  0.19238476,\n",
              "  0.19318637,\n",
              "  0.19318637,\n",
              "  0.19559118,\n",
              "  0.1987976,\n",
              "  0.1991984,\n",
              "  0.19959919],\n",
              " 'val_loss': [7.247240815843854,\n",
              "  6.966986792428153,\n",
              "  6.719614233289446,\n",
              "  6.5207295417785645,\n",
              "  6.3583583150591165,\n",
              "  6.2230314527239114,\n",
              "  6.11152069909232,\n",
              "  6.020244325910296,\n",
              "  5.940366404397147,\n",
              "  5.869107791355678,\n",
              "  5.80966717856271,\n",
              "  5.759131159101214,\n",
              "  5.714914798736572,\n",
              "  5.676181725093296,\n",
              "  5.640345573425293,\n",
              "  5.6073320252554755,\n",
              "  5.576616695949009,\n",
              "  5.548392227717808,\n",
              "  5.521646772112165,\n",
              "  5.495735372815814,\n",
              "  5.471408843994141,\n",
              "  5.448387895311628,\n",
              "  5.428212574550083,\n",
              "  5.408613545554025,\n",
              "  5.390506403786795,\n",
              "  5.374123573303223,\n",
              "  5.359176976340158,\n",
              "  5.345556667872837,\n",
              "  5.333044597080776,\n",
              "  5.321504865373884,\n",
              "  5.310794762202671,\n",
              "  5.300647667476109,\n",
              "  5.290773596082415,\n",
              "  5.281384604317801,\n",
              "  5.272462163652692,\n",
              "  5.263833114079067,\n",
              "  5.255429880959647,\n",
              "  5.247353417532785,\n",
              "  5.239506925855364,\n",
              "  5.23205954687936],\n",
              " 'val_perplexity': [1243.4751,\n",
              "  782.4622,\n",
              "  692.241,\n",
              "  624.09845,\n",
              "  574.31866,\n",
              "  541.0555,\n",
              "  499.723,\n",
              "  466.28848,\n",
              "  435.29904,\n",
              "  408.51263,\n",
              "  386.81982,\n",
              "  370.1932,\n",
              "  358.204,\n",
              "  350.996,\n",
              "  347.30875,\n",
              "  346.96036,\n",
              "  348.05566,\n",
              "  349.50885,\n",
              "  350.70654,\n",
              "  351.5427,\n",
              "  351.49133,\n",
              "  352.22806,\n",
              "  355.4661,\n",
              "  358.4945,\n",
              "  362.81573,\n",
              "  367.81488,\n",
              "  373.1687,\n",
              "  378.4469,\n",
              "  383.48114,\n",
              "  388.629,\n",
              "  394.07645,\n",
              "  400.2795,\n",
              "  407.6436,\n",
              "  416.76614,\n",
              "  426.70197,\n",
              "  439.3808,\n",
              "  451.6745,\n",
              "  467.698,\n",
              "  482.07376,\n",
              "  498.2344]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IQuXd8JZptB7",
        "colab_type": "code",
        "outputId": "ae245c01-24a8-4e35-cdaa-356c2cf78dc3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        }
      },
      "source": [
        "#Loading the saved model\n",
        "# # dependencies = {\n",
        "# #     'perplexity': perplexity\n",
        "# # }\n",
        "# model = tf.keras.models.load_model('drive/My Drive/Next Word Prediction/model_seq5.h5',custom_objects=dependencies)\n",
        "# model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "cu_dnnlstm (CuDNNLSTM)       (None, 50)                70400     \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 77826)             3969126   \n",
            "=================================================================\n",
            "Total params: 4,039,526\n",
            "Trainable params: 4,039,526\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZoeqtOKyp8NU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# #Load the model history\n",
        "# from pickle import load\n",
        "# with open('drive/My Drive/Next Word Prediction/trainHistory', 'rb') as handle:\n",
        "#     history = load(handle)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IuimcuWTHt6X",
        "colab_type": "text"
      },
      "source": [
        "Evaluate the Model on Testing data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IIbWkUR4qGaE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 16\n",
        "testGenerator = KerastestBatchGenerator(test[0:1000],vocab_size,batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_soUjAkRavFL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import heapq"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rGo_micGqJTR",
        "colab_type": "code",
        "outputId": "fb753354-36f2-4278-80af-da2c4be16562",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        }
      },
      "source": [
        "test_columns = [\"sentence\",\"ground_truth\"]\n",
        "for i in range(1,11):\n",
        "    test_columns.append(\"pred_\"+str(i))\n",
        "test_columns"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['sentence',\n",
              " 'ground_truth',\n",
              " 'pred_1',\n",
              " 'pred_2',\n",
              " 'pred_3',\n",
              " 'pred_4',\n",
              " 'pred_5',\n",
              " 'pred_6',\n",
              " 'pred_7',\n",
              " 'pred_8',\n",
              " 'pred_9',\n",
              " 'pred_10']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VlRyvquJqLya",
        "colab_type": "code",
        "outputId": "1e2e1ef6-7918-47b8-b1c2-55d1d4bb19ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "test_accuracy = 0\n",
        "test_accuracy_top5 = 0\n",
        "test_accuracy_top10 = 0\n",
        "total = 0\n",
        "import math\n",
        "for i in range(0,math.ceil(len(test[0:1000])/(batch_size))):\n",
        "    print(\"Batch\",str(i+1),\"out of \",str(math.ceil(len(test[0:1000])/(batch_size))))\n",
        "    df_pred = pd.DataFrame(columns=test_columns)\n",
        "    (tempx,tempy,sen) = next(testGenerator.generate())\n",
        "    tempx = tempx.reshape(-1,seq_len,300)\n",
        "    numRows = tempx.shape[0]\n",
        "    test_pred = model.predict_on_batch(tempx)\n",
        "    y_test = [word_map[item[-1]] for item in sen]\n",
        "    for j in range(numRows):\n",
        "        pp = np.argmax(test_pred[j])\n",
        "\n",
        "        total+=1\n",
        "        temp = (-test_pred[j]).argsort()[:10]\n",
        "        #Calculate Accuracies\n",
        "        if(y_test[j] in temp):\n",
        "            test_accuracy_top10+=1\n",
        "        if(y_test[j] in temp[0:5]):\n",
        "            test_accuracy_top5+=1\n",
        "            if(y_test[j] == temp[0]):\n",
        "                test_accuracy+=1\n",
        "        row = {}\n",
        "        row['sentence'] = sen[j][:-1]\n",
        "        row['ground_truth'] = inverse_word_map[y_test[j]]\n",
        "        for k in range(len(temp)):\n",
        "            row['pred_'+str(k+1)] = inverse_word_map[temp[k]]\n",
        "        df_pred = df_pred.append(row , ignore_index=True)\n",
        "    df_pred.to_csv(\"drive/My Drive/Next Word Prediction/predictions_batch_\"+str(i)+\".csv\")\n",
        "    print(\"Accuracy=\",str(test_accuracy/total))\n",
        "    print(\"Top5Accuaracy=\",str(test_accuracy_top5/total))\n",
        "    print(\"Top10Accuaracy=\",str(test_accuracy_top10/total))\n",
        "    print(\"total=\",str(total))\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Batch 1 out of  63\n",
            "Accuracy= 0.18952618453865336\n",
            "Top5Accuaracy= 0.32418952618453867\n",
            "Top10Accuaracy= 0.39900249376558605\n",
            "total= 401\n",
            "Batch 2 out of  63\n",
            "Accuracy= 0.17232704402515722\n",
            "Top5Accuaracy= 0.31572327044025156\n",
            "Top10Accuaracy= 0.389937106918239\n",
            "total= 795\n",
            "Batch 3 out of  63\n",
            "Accuracy= 0.17757847533632287\n",
            "Top5Accuaracy= 0.3237668161434978\n",
            "Top10Accuaracy= 0.3919282511210762\n",
            "total= 1115\n",
            "Batch 4 out of  63\n",
            "Accuracy= 0.1845042678923178\n",
            "Top5Accuaracy= 0.3315824031516743\n",
            "Top10Accuaracy= 0.40840446487196325\n",
            "total= 1523\n",
            "Batch 5 out of  63\n",
            "Accuracy= 0.18245425188374598\n",
            "Top5Accuaracy= 0.3240043057050592\n",
            "Top10Accuaracy= 0.4015069967707212\n",
            "total= 1858\n",
            "Batch 6 out of  63\n",
            "Accuracy= 0.19075937785910338\n",
            "Top5Accuaracy= 0.33989021043000917\n",
            "Top10Accuaracy= 0.41765782250686184\n",
            "total= 2186\n",
            "Batch 7 out of  63\n",
            "Accuracy= 0.18948983505945532\n",
            "Top5Accuaracy= 0.34023782125047947\n",
            "Top10Accuaracy= 0.41503644035289605\n",
            "total= 2607\n",
            "Batch 8 out of  63\n",
            "Accuracy= 0.1922043010752688\n",
            "Top5Accuaracy= 0.34038978494623656\n",
            "Top10Accuaracy= 0.4163306451612903\n",
            "total= 2976\n",
            "Batch 9 out of  63\n",
            "Accuracy= 0.19135802469135801\n",
            "Top5Accuaracy= 0.34332745443856555\n",
            "Top10Accuaracy= 0.41887125220458554\n",
            "total= 3402\n",
            "Batch 10 out of  63\n",
            "Accuracy= 0.1889039242219215\n",
            "Top5Accuaracy= 0.3412719891745602\n",
            "Top10Accuaracy= 0.4173207036535859\n",
            "total= 3695\n",
            "Batch 11 out of  63\n",
            "Accuracy= 0.18642005354100755\n",
            "Top5Accuaracy= 0.3343879289364809\n",
            "Top10Accuaracy= 0.41031881236310536\n",
            "total= 4109\n",
            "Batch 12 out of  63\n",
            "Accuracy= 0.18473180503004674\n",
            "Top5Accuaracy= 0.330514133095927\n",
            "Top10Accuaracy= 0.4061874026263076\n",
            "total= 4493\n",
            "Batch 13 out of  63\n",
            "Accuracy= 0.1856312292358804\n",
            "Top5Accuaracy= 0.329734219269103\n",
            "Top10Accuaracy= 0.4063538205980066\n",
            "total= 4816\n",
            "Batch 14 out of  63\n",
            "Accuracy= 0.18356744275543582\n",
            "Top5Accuaracy= 0.3261497017510102\n",
            "Top10Accuaracy= 0.4033096016932846\n",
            "total= 5197\n",
            "Batch 15 out of  63\n",
            "Accuracy= 0.1817035836484783\n",
            "Top5Accuaracy= 0.3248694399423735\n",
            "Top10Accuaracy= 0.40086439762290654\n",
            "total= 5553\n",
            "Batch 16 out of  63\n",
            "Accuracy= 0.1802669369825984\n",
            "Top5Accuaracy= 0.3245480655516135\n",
            "Top10Accuaracy= 0.39922284169623246\n",
            "total= 5919\n",
            "Batch 17 out of  63\n",
            "Accuracy= 0.1801583454516077\n",
            "Top5Accuaracy= 0.32444659880433024\n",
            "Top10Accuaracy= 0.3979641299079011\n",
            "total= 6189\n",
            "Batch 18 out of  63\n",
            "Accuracy= 0.1820269442743417\n",
            "Top5Accuaracy= 0.3263931414574403\n",
            "Top10Accuaracy= 0.4009491733006736\n",
            "total= 6532\n",
            "Batch 19 out of  63\n",
            "Accuracy= 0.1802181818181818\n",
            "Top5Accuaracy= 0.32494545454545454\n",
            "Top10Accuaracy= 0.3992727272727273\n",
            "total= 6875\n",
            "Batch 20 out of  63\n",
            "Accuracy= 0.17934633342488326\n",
            "Top5Accuaracy= 0.3266959626476243\n",
            "Top10Accuaracy= 0.40002746498214775\n",
            "total= 7282\n",
            "Batch 21 out of  63\n",
            "Accuracy= 0.17755181853734844\n",
            "Top5Accuaracy= 0.32407769521574764\n",
            "Top10Accuaracy= 0.3968191891539565\n",
            "total= 7671\n",
            "Batch 22 out of  63\n",
            "Accuracy= 0.17523975588491716\n",
            "Top5Accuaracy= 0.3204633204633205\n",
            "Top10Accuaracy= 0.3930751027525221\n",
            "total= 8029\n",
            "Batch 23 out of  63\n",
            "Accuracy= 0.1739959480395662\n",
            "Top5Accuaracy= 0.31867477058753424\n",
            "Top10Accuaracy= 0.3905374806340126\n",
            "total= 8391\n",
            "Batch 24 out of  63\n",
            "Accuracy= 0.174839596700275\n",
            "Top5Accuaracy= 0.3193171402383135\n",
            "Top10Accuaracy= 0.391269477543538\n",
            "total= 8728\n",
            "Batch 25 out of  63\n",
            "Accuracy= 0.17524324324324325\n",
            "Top5Accuaracy= 0.31891891891891894\n",
            "Top10Accuaracy= 0.39232432432432435\n",
            "total= 9250\n",
            "Batch 26 out of  63\n",
            "Accuracy= 0.17276946879834967\n",
            "Top5Accuaracy= 0.31531717380092833\n",
            "Top10Accuaracy= 0.3887570912841671\n",
            "total= 9695\n",
            "Batch 27 out of  63\n",
            "Accuracy= 0.17234169653524492\n",
            "Top5Accuaracy= 0.3171047391477499\n",
            "Top10Accuaracy= 0.3896853843090402\n",
            "total= 10044\n",
            "Batch 28 out of  63\n",
            "Accuracy= 0.17419664268585133\n",
            "Top5Accuaracy= 0.32354916067146283\n",
            "Top10Accuaracy= 0.3953956834532374\n",
            "total= 10425\n",
            "Batch 29 out of  63\n",
            "Accuracy= 0.17330750783988194\n",
            "Top5Accuaracy= 0.32208079690094077\n",
            "Top10Accuaracy= 0.39346983951300496\n",
            "total= 10842\n",
            "Batch 30 out of  63\n",
            "Accuracy= 0.17180031864046733\n",
            "Top5Accuaracy= 0.31996813595326606\n",
            "Top10Accuaracy= 0.3911311736590547\n",
            "total= 11298\n",
            "Batch 31 out of  63\n",
            "Accuracy= 0.17247831263820376\n",
            "Top5Accuaracy= 0.32029256676305495\n",
            "Top10Accuaracy= 0.3913930940636163\n",
            "total= 11758\n",
            "Batch 32 out of  63\n",
            "Accuracy= 0.1721614733207268\n",
            "Top5Accuaracy= 0.32154895996053606\n",
            "Top10Accuaracy= 0.3925840664309792\n",
            "total= 12163\n",
            "Batch 33 out of  63\n",
            "Accuracy= 0.17301536491677336\n",
            "Top5Accuaracy= 0.3218629961587708\n",
            "Top10Accuaracy= 0.3926056338028169\n",
            "total= 12496\n",
            "Batch 34 out of  63\n",
            "Accuracy= 0.17222695255050702\n",
            "Top5Accuaracy= 0.32115488814923754\n",
            "Top10Accuaracy= 0.39120674974843256\n",
            "total= 12919\n",
            "Batch 35 out of  63\n",
            "Accuracy= 0.1719596628537026\n",
            "Top5Accuaracy= 0.3200632149307646\n",
            "Top10Accuaracy= 0.39020168573148706\n",
            "total= 13288\n",
            "Batch 36 out of  63\n",
            "Accuracy= 0.17212457151192473\n",
            "Top5Accuaracy= 0.3207643497921377\n",
            "Top10Accuaracy= 0.39107286120633067\n",
            "total= 13711\n",
            "Batch 37 out of  63\n",
            "Accuracy= 0.17199121626407876\n",
            "Top5Accuaracy= 0.3206063611248849\n",
            "Top10Accuaracy= 0.3900970461146136\n",
            "total= 14117\n",
            "Batch 38 out of  63\n",
            "Accuracy= 0.17248289682813903\n",
            "Top5Accuaracy= 0.3212632160873471\n",
            "Top10Accuaracy= 0.3909888743003248\n",
            "total= 14471\n",
            "Batch 39 out of  63\n",
            "Accuracy= 0.17334319128915177\n",
            "Top5Accuaracy= 0.3240354886409464\n",
            "Top10Accuaracy= 0.3937357171662858\n",
            "total= 14878\n",
            "Batch 40 out of  63\n",
            "Accuracy= 0.17409353311279757\n",
            "Top5Accuaracy= 0.3250308101446455\n",
            "Top10Accuaracy= 0.3950184860867873\n",
            "total= 15417\n",
            "Batch 41 out of  63\n",
            "Accuracy= 0.17381389751061\n",
            "Top5Accuaracy= 0.3247608792044087\n",
            "Top10Accuaracy= 0.39481852156837904\n",
            "total= 15787\n",
            "Batch 42 out of  63\n",
            "Accuracy= 0.17301763472684673\n",
            "Top5Accuaracy= 0.32309779257614996\n",
            "Top10Accuaracy= 0.39357504007892463\n",
            "total= 16218\n",
            "Batch 43 out of  63\n",
            "Accuracy= 0.17195719209142027\n",
            "Top5Accuaracy= 0.32172440897273114\n",
            "Top10Accuaracy= 0.39204304976117055\n",
            "total= 16539\n",
            "Batch 44 out of  63\n",
            "Accuracy= 0.1723564685626076\n",
            "Top5Accuaracy= 0.3214985453897762\n",
            "Top10Accuaracy= 0.39197292643828296\n",
            "total= 16843\n",
            "Batch 45 out of  63\n",
            "Accuracy= 0.1723337588487873\n",
            "Top5Accuaracy= 0.32076128583033536\n",
            "Top10Accuaracy= 0.391725658581873\n",
            "total= 17234\n",
            "Batch 46 out of  63\n",
            "Accuracy= 0.172400045563276\n",
            "Top5Accuaracy= 0.32139195808178606\n",
            "Top10Accuaracy= 0.39201503588107983\n",
            "total= 17558\n",
            "Batch 47 out of  63\n",
            "Accuracy= 0.1726320506357475\n",
            "Top5Accuaracy= 0.3211225004200975\n",
            "Top10Accuaracy= 0.3920349521088893\n",
            "total= 17853\n",
            "Batch 48 out of  63\n",
            "Accuracy= 0.17219338978421198\n",
            "Top5Accuaracy= 0.32029500136574707\n",
            "Top10Accuaracy= 0.39142310844031686\n",
            "total= 18305\n",
            "Batch 49 out of  63\n",
            "Accuracy= 0.17220495229928182\n",
            "Top5Accuaracy= 0.31996998606495874\n",
            "Top10Accuaracy= 0.3911458891628256\n",
            "total= 18658\n",
            "Batch 50 out of  63\n",
            "Accuracy= 0.1709869078290131\n",
            "Top5Accuaracy= 0.31836584468163415\n",
            "Top10Accuaracy= 0.3892423366107577\n",
            "total= 19019\n",
            "Batch 51 out of  63\n",
            "Accuracy= 0.17365793401616142\n",
            "Top5Accuaracy= 0.3212208554223069\n",
            "Top10Accuaracy= 0.3926604560193525\n",
            "total= 19429\n",
            "Batch 52 out of  63\n",
            "Accuracy= 0.1769439694195755\n",
            "Top5Accuaracy= 0.3247158233578111\n",
            "Top10Accuaracy= 0.39653958354290314\n",
            "total= 19882\n",
            "Batch 53 out of  63\n",
            "Accuracy= 0.17700648611179878\n",
            "Top5Accuaracy= 0.3249987621924048\n",
            "Top10Accuaracy= 0.3970391642323117\n",
            "total= 20197\n",
            "Batch 54 out of  63\n",
            "Accuracy= 0.17633072929302732\n",
            "Top5Accuaracy= 0.32422727934397594\n",
            "Top10Accuaracy= 0.396622834683876\n",
            "total= 20609\n",
            "Batch 55 out of  63\n",
            "Accuracy= 0.17687010211351223\n",
            "Top5Accuaracy= 0.3244834956067442\n",
            "Top10Accuaracy= 0.39715032058893374\n",
            "total= 21055\n",
            "Batch 56 out of  63\n",
            "Accuracy= 0.17652287826331056\n",
            "Top5Accuaracy= 0.32361747918031253\n",
            "Top10Accuaracy= 0.3967437073079442\n",
            "total= 21374\n",
            "Batch 57 out of  63\n",
            "Accuracy= 0.1775413819982576\n",
            "Top5Accuaracy= 0.3246366179100371\n",
            "Top10Accuaracy= 0.39763400431014717\n",
            "total= 21809\n",
            "Batch 58 out of  63\n",
            "Accuracy= 0.17744272389749163\n",
            "Top5Accuaracy= 0.32450421081227926\n",
            "Top10Accuaracy= 0.39726523589604273\n",
            "total= 22086\n",
            "Batch 59 out of  63\n",
            "Accuracy= 0.17706183254060845\n",
            "Top5Accuaracy= 0.3238355918513865\n",
            "Top10Accuaracy= 0.3969308085793772\n",
            "total= 22286\n",
            "Batch 60 out of  63\n",
            "Accuracy= 0.1765764184474966\n",
            "Top5Accuaracy= 0.3229189521260257\n",
            "Top10Accuaracy= 0.3963315634736057\n",
            "total= 22789\n",
            "Batch 61 out of  63\n",
            "Accuracy= 0.17644015177647465\n",
            "Top5Accuaracy= 0.32261124525698515\n",
            "Top10Accuaracy= 0.39638668506381514\n",
            "total= 23192\n",
            "Batch 62 out of  63\n",
            "Accuracy= 0.17651287689770373\n",
            "Top5Accuaracy= 0.3230430921469954\n",
            "Top10Accuaracy= 0.3967522307269421\n",
            "total= 23647\n",
            "Batch 63 out of  63\n",
            "Accuracy= 0.17643856269369293\n",
            "Top5Accuaracy= 0.3227238462182762\n",
            "Top10Accuaracy= 0.39659938018259483\n",
            "total= 23878\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fmZ9QYTHqLvq",
        "colab_type": "code",
        "outputId": "af318531-c965-421e-e25d-f0573670b4da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "print(test_accuracy/total)\n",
        "print(test_accuracy_top5/total)\n",
        "print(test_accuracy_top10/total)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.17643856269369293\n",
            "0.3227238462182762\n",
            "0.39659938018259483\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xu_G8cSfH9qs",
        "colab_type": "text"
      },
      "source": [
        "LSTM with Sentiment Filtering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H6jdYhD2o_S_",
        "colab_type": "code",
        "outputId": "bb130836-0025-4aed-b67d-d52659d55d3d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "!pip install vaderSentiment\n",
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
        "analyser = SentimentIntensityAnalyzer()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting vaderSentiment\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/86/9e/c53e1fc61aac5ee490a6ac5e21b1ac04e55a7c2aba647bb8411c9aadf24e/vaderSentiment-3.2.1-py2.py3-none-any.whl (125kB)\n",
            "\r\u001b[K     |██▋                             | 10kB 19.3MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 20kB 1.8MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 30kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 40kB 1.8MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 51kB 2.2MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 61kB 2.6MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 71kB 3.0MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 81kB 3.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 92kB 3.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 102kB 2.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 112kB 2.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 122kB 2.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 133kB 2.9MB/s \n",
            "\u001b[?25hInstalling collected packages: vaderSentiment\n",
            "Successfully installed vaderSentiment-3.2.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "606hyRogpN1f",
        "colab_type": "code",
        "outputId": "1e014c2b-48fd-430f-f024-d9f87c3c0280",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "analyser.polarity_scores(\"bad\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'compound': -0.5423, 'neg': 1.0, 'neu': 0.0, 'pos': 0.0}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uG3pAciaqUS_",
        "colab_type": "text"
      },
      "source": [
        "Testing Accuracy using Sentiment "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZqFpLxytbQS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentiment_map = dict()\n",
        "for num,word in inverse_word_map.items():\n",
        "  sentiment_map[num] = analyser.polarity_scores(word)  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h4wnaIRvvF5g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 16\n",
        "testSentGenerator = KerastestBatchGenerator(test[0:1000],vocab_size,batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b41njuolqTAk",
        "colab_type": "code",
        "outputId": "e3ea9313-4e8a-4489-c344-1366b9b81f49",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "test_accuracy_sentiment = 0\n",
        "test_accuracy_top5_sentiment = 0\n",
        "test_accuracy_top10_sentiment = 0\n",
        "total_sentiment = 0\n",
        "import math\n",
        "for i in range(0,math.ceil(len(test[0:1000])/(batch_size))):\n",
        "    print(\"Batch\",str(i+1),\"out of \",str(math.ceil(len(test[0:1000])/(batch_size))))\n",
        "    \n",
        "    df_pred = pd.DataFrame(columns=test_columns)\n",
        "    (tempx,tempy,sen) = next(testSentGenerator.generate())\n",
        "    tempx = tempx.reshape(-1,seq_len,300)\n",
        "    numRows = tempx.shape[0]\n",
        "    test_pred = model.predict_on_batch(tempx)\n",
        "    \n",
        "    y_test = [word_map[item[-1]] for item in sen]\n",
        "    for j in range(numRows):\n",
        "        total_sentiment+=1\n",
        "        prevSentiment = analyser.polarity_scores(''.join(sen[j][:-1]))\n",
        "        \n",
        "        top20 = (-test_pred[j]).argsort()[:20]\n",
        "        valMap = {}\n",
        "        for p in top20:\n",
        "          vl=test_pred[j][p] + (2-abs(sentiment_map[p]['compound']-prevSentiment['compound']))\n",
        "          valMap[p] = vl\n",
        "        top10_sent = sorted(valMap.items(), key=lambda kv: kv[1], reverse=True)[0:10]\n",
        "        temp = []\n",
        "        for x in top10_sent:\n",
        "          temp.append(x[0])\n",
        "        #Calculate Accuracies\n",
        "        if(y_test[j] in temp):\n",
        "            test_accuracy_top10_sentiment+=1\n",
        "        if(y_test[j] in temp[0:5]):\n",
        "            test_accuracy_top5_sentiment+=1\n",
        "            if(y_test[j] == temp[0]):\n",
        "                test_accuracy_sentiment+=1\n",
        "        row = {}\n",
        "        row['sentence'] = sen[j][:-1]\n",
        "        row['ground_truth'] = inverse_word_map[y_test[j]]\n",
        "        for k in range(len(temp)):\n",
        "            row['pred_'+str(k+1)] = inverse_word_map[temp[k]]\n",
        "        df_pred = df_pred.append(row , ignore_index=True)\n",
        "    df_pred.to_csv(\"drive/My Drive/Next Word Prediction/predictions_batch_\"+str(i)+\".csv\")\n",
        "    print(\"Accuracy=\",str(test_accuracy_sentiment/total_sentiment))\n",
        "    print(\"Top5Accuaracy=\",str(test_accuracy_top5_sentiment/total_sentiment))\n",
        "    print(\"Top10Accuaracy=\",str(test_accuracy_top10_sentiment/total_sentiment))\n",
        "    print(\"total=\",str(total_sentiment))\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Batch 1 out of  63\n",
            "Accuracy= 0.18703241895261846\n",
            "Top5Accuaracy= 0.32169576059850374\n",
            "Top10Accuaracy= 0.40648379052369077\n",
            "total= 401\n",
            "Batch 2 out of  63\n",
            "Accuracy= 0.1710691823899371\n",
            "Top5Accuaracy= 0.3119496855345912\n",
            "Top10Accuaracy= 0.3937106918238994\n",
            "total= 795\n",
            "Batch 3 out of  63\n",
            "Accuracy= 0.17668161434977578\n",
            "Top5Accuaracy= 0.31928251121076234\n",
            "Top10Accuaracy= 0.39820627802690584\n",
            "total= 1115\n",
            "Batch 4 out of  63\n",
            "Accuracy= 0.18319107025607353\n",
            "Top5Accuaracy= 0.325016414970453\n",
            "Top10Accuaracy= 0.41168745896257386\n",
            "total= 1523\n",
            "Batch 5 out of  63\n",
            "Accuracy= 0.18083961248654468\n",
            "Top5Accuaracy= 0.3153928955866523\n",
            "Top10Accuaracy= 0.4041980624327234\n",
            "total= 1858\n",
            "Batch 6 out of  63\n",
            "Accuracy= 0.18847209515096067\n",
            "Top5Accuaracy= 0.32936870997255263\n",
            "Top10Accuaracy= 0.4172003659652333\n",
            "total= 2186\n",
            "Batch 7 out of  63\n",
            "Accuracy= 0.18757192174913695\n",
            "Top5Accuaracy= 0.32988108937476024\n",
            "Top10Accuaracy= 0.412734944380514\n",
            "total= 2607\n",
            "Batch 8 out of  63\n",
            "Accuracy= 0.1905241935483871\n",
            "Top5Accuaracy= 0.3299731182795699\n",
            "Top10Accuaracy= 0.4112903225806452\n",
            "total= 2976\n",
            "Batch 9 out of  63\n",
            "Accuracy= 0.18930041152263374\n",
            "Top5Accuaracy= 0.3324514991181658\n",
            "Top10Accuaracy= 0.4124044679600235\n",
            "total= 3402\n",
            "Batch 10 out of  63\n",
            "Accuracy= 0.186468200270636\n",
            "Top5Accuaracy= 0.3309878213802436\n",
            "Top10Accuaracy= 0.4110960757780785\n",
            "total= 3695\n",
            "Batch 11 out of  63\n",
            "Accuracy= 0.1839863713798978\n",
            "Top5Accuaracy= 0.32489656850815285\n",
            "Top10Accuaracy= 0.40496471160866393\n",
            "total= 4109\n",
            "Batch 12 out of  63\n",
            "Accuracy= 0.18228355219229914\n",
            "Top5Accuaracy= 0.32138882706432226\n",
            "Top10Accuaracy= 0.4001780547518362\n",
            "total= 4493\n",
            "Batch 13 out of  63\n",
            "Accuracy= 0.18313953488372092\n",
            "Top5Accuaracy= 0.32122093023255816\n",
            "Top10Accuaracy= 0.3995016611295681\n",
            "total= 4816\n",
            "Batch 14 out of  63\n",
            "Accuracy= 0.18087358091206465\n",
            "Top5Accuaracy= 0.316913604002309\n",
            "Top10Accuaracy= 0.39484317875697517\n",
            "total= 5197\n",
            "Batch 15 out of  63\n",
            "Accuracy= 0.17900234107689536\n",
            "Top5Accuaracy= 0.3156852151989915\n",
            "Top10Accuaracy= 0.3927606699081578\n",
            "total= 5553\n",
            "Batch 16 out of  63\n",
            "Accuracy= 0.17756377766514614\n",
            "Top5Accuaracy= 0.315424902855212\n",
            "Top10Accuaracy= 0.3911133637438757\n",
            "total= 5919\n",
            "Batch 17 out of  63\n",
            "Accuracy= 0.177573113588625\n",
            "Top5Accuaracy= 0.3157214412667636\n",
            "Top10Accuaracy= 0.39020843431895297\n",
            "total= 6189\n",
            "Batch 18 out of  63\n",
            "Accuracy= 0.17911818738518065\n",
            "Top5Accuaracy= 0.3178199632578077\n",
            "Top10Accuaracy= 0.39237599510104104\n",
            "total= 6532\n",
            "Batch 19 out of  63\n",
            "Accuracy= 0.17701818181818182\n",
            "Top5Accuaracy= 0.3160727272727273\n",
            "Top10Accuaracy= 0.3906909090909091\n",
            "total= 6875\n",
            "Batch 20 out of  63\n",
            "Accuracy= 0.17632518538862949\n",
            "Top5Accuaracy= 0.3184564680032958\n",
            "Top10Accuaracy= 0.39178797033781926\n",
            "total= 7282\n",
            "Batch 21 out of  63\n",
            "Accuracy= 0.17455351323165166\n",
            "Top5Accuaracy= 0.31612566810063875\n",
            "Top10Accuaracy= 0.3888671620388476\n",
            "total= 7671\n",
            "Batch 22 out of  63\n",
            "Accuracy= 0.17225059160543033\n",
            "Top5Accuaracy= 0.3123676672063769\n",
            "Top10Accuaracy= 0.3852285465188691\n",
            "total= 8029\n",
            "Batch 23 out of  63\n",
            "Accuracy= 0.17101656536765583\n",
            "Top5Accuaracy= 0.3109283756405673\n",
            "Top10Accuaracy= 0.3824335597664164\n",
            "total= 8391\n",
            "Batch 24 out of  63\n",
            "Accuracy= 0.17197525206232814\n",
            "Top5Accuaracy= 0.31164069660861593\n",
            "Top10Accuaracy= 0.38256186984417967\n",
            "total= 8728\n",
            "Batch 25 out of  63\n",
            "Accuracy= 0.17243243243243242\n",
            "Top5Accuaracy= 0.31048648648648647\n",
            "Top10Accuaracy= 0.3825945945945946\n",
            "total= 9250\n",
            "Batch 26 out of  63\n",
            "Accuracy= 0.1699845281072718\n",
            "Top5Accuaracy= 0.3070654976792161\n",
            "Top10Accuaracy= 0.378751933986591\n",
            "total= 9695\n",
            "Batch 27 out of  63\n",
            "Accuracy= 0.16965352449223417\n",
            "Top5Accuaracy= 0.30904022301871764\n",
            "Top10Accuaracy= 0.37972919155714857\n",
            "total= 10044\n",
            "Batch 28 out of  63\n",
            "Accuracy= 0.17160671462829735\n",
            "Top5Accuaracy= 0.3156834532374101\n",
            "Top10Accuaracy= 0.38580335731414866\n",
            "total= 10425\n",
            "Batch 29 out of  63\n",
            "Accuracy= 0.17072495849474267\n",
            "Top5Accuaracy= 0.3142409149603394\n",
            "Top10Accuaracy= 0.3836008116583656\n",
            "total= 10842\n",
            "Batch 30 out of  63\n",
            "Accuracy= 0.169233492653567\n",
            "Top5Accuaracy= 0.3119136130288547\n",
            "Top10Accuaracy= 0.38077535847052574\n",
            "total= 11298\n",
            "Batch 31 out of  63\n",
            "Accuracy= 0.16984180983160402\n",
            "Top5Accuaracy= 0.3119578159550944\n",
            "Top10Accuaracy= 0.3801666950161592\n",
            "total= 11758\n",
            "Batch 32 out of  63\n",
            "Accuracy= 0.169612760009866\n",
            "Top5Accuaracy= 0.3134095206774644\n",
            "Top10Accuaracy= 0.38156704760338733\n",
            "total= 12163\n",
            "Batch 33 out of  63\n",
            "Accuracy= 0.1705345710627401\n",
            "Top5Accuaracy= 0.31370038412291934\n",
            "Top10Accuaracy= 0.38156209987195905\n",
            "total= 12496\n",
            "Batch 34 out of  63\n",
            "Accuracy= 0.169749980648657\n",
            "Top5Accuaracy= 0.31279510798049387\n",
            "Top10Accuaracy= 0.3802151869339732\n",
            "total= 12919\n",
            "Batch 35 out of  63\n",
            "Accuracy= 0.1694762191450933\n",
            "Top5Accuaracy= 0.3118603251053582\n",
            "Top10Accuaracy= 0.3792895845875978\n",
            "total= 13288\n",
            "Batch 36 out of  63\n",
            "Accuracy= 0.16964481073590548\n",
            "Top5Accuaracy= 0.3126686601998395\n",
            "Top10Accuaracy= 0.38027860841659983\n",
            "total= 13711\n",
            "Batch 37 out of  63\n",
            "Accuracy= 0.16951193596373168\n",
            "Top5Accuaracy= 0.31267266416377415\n",
            "Top10Accuaracy= 0.37968406885315575\n",
            "total= 14117\n",
            "Batch 38 out of  63\n",
            "Accuracy= 0.17006426646396242\n",
            "Top5Accuaracy= 0.3132471840232188\n",
            "Top10Accuaracy= 0.38027779697325687\n",
            "total= 14471\n",
            "Batch 39 out of  63\n",
            "Accuracy= 0.17099072455975264\n",
            "Top5Accuaracy= 0.31603710176098937\n",
            "Top10Accuaracy= 0.38311601021642694\n",
            "total= 14878\n",
            "Batch 40 out of  63\n",
            "Accuracy= 0.17175844846597912\n",
            "Top5Accuaracy= 0.31685801388078094\n",
            "Top10Accuaracy= 0.38379710708957643\n",
            "total= 15417\n",
            "Batch 41 out of  63\n",
            "Accuracy= 0.1714701969975296\n",
            "Top5Accuaracy= 0.3165262557800722\n",
            "Top10Accuaracy= 0.3834800785456388\n",
            "total= 15787\n",
            "Batch 42 out of  63\n",
            "Accuracy= 0.17061289924774942\n",
            "Top5Accuaracy= 0.3149586878776668\n",
            "Top10Accuaracy= 0.38222962140831174\n",
            "total= 16218\n",
            "Batch 43 out of  63\n",
            "Accuracy= 0.16959912933067295\n",
            "Top5Accuaracy= 0.31362234717939413\n",
            "Top10Accuaracy= 0.38103875687768307\n",
            "total= 16539\n",
            "Batch 44 out of  63\n",
            "Accuracy= 0.1699815947277801\n",
            "Top5Accuaracy= 0.31360208988897464\n",
            "Top10Accuaracy= 0.3808703912604643\n",
            "total= 16843\n",
            "Batch 45 out of  63\n",
            "Accuracy= 0.16995474062898921\n",
            "Top5Accuaracy= 0.3129279331553905\n",
            "Top10Accuaracy= 0.3807589648369502\n",
            "total= 17234\n",
            "Batch 46 out of  63\n",
            "Accuracy= 0.1699510194783005\n",
            "Top5Accuaracy= 0.31347533887686524\n",
            "Top10Accuaracy= 0.3808520332611915\n",
            "total= 17558\n",
            "Batch 47 out of  63\n",
            "Accuracy= 0.17005545286506468\n",
            "Top5Accuaracy= 0.3132806811180194\n",
            "Top10Accuaracy= 0.38055228813084635\n",
            "total= 17853\n",
            "Batch 48 out of  63\n",
            "Accuracy= 0.1696257853045616\n",
            "Top5Accuaracy= 0.3124829281617045\n",
            "Top10Accuaracy= 0.3802239825184376\n",
            "total= 18305\n",
            "Batch 49 out of  63\n",
            "Accuracy= 0.16957873298317075\n",
            "Top5Accuaracy= 0.31203773180405187\n",
            "Top10Accuaracy= 0.3798906635223497\n",
            "total= 18658\n",
            "Batch 50 out of  63\n",
            "Accuracy= 0.16841053683158946\n",
            "Top5Accuaracy= 0.31058415268941586\n",
            "Top10Accuaracy= 0.3780955886219044\n",
            "total= 19019\n",
            "Batch 51 out of  63\n",
            "Accuracy= 0.1706727057491379\n",
            "Top5Accuaracy= 0.3126254567913943\n",
            "Top10Accuaracy= 0.3806680734983787\n",
            "total= 19429\n",
            "Batch 52 out of  63\n",
            "Accuracy= 0.17367468061563224\n",
            "Top5Accuaracy= 0.3156624082084297\n",
            "Top10Accuaracy= 0.3841665828387486\n",
            "total= 19882\n",
            "Batch 53 out of  63\n",
            "Accuracy= 0.17378818636431154\n",
            "Top5Accuaracy= 0.315838985988018\n",
            "Top10Accuaracy= 0.3846610882804377\n",
            "total= 20197\n",
            "Batch 54 out of  63\n",
            "Accuracy= 0.1731767674317046\n",
            "Top5Accuaracy= 0.3152020961715755\n",
            "Top10Accuaracy= 0.3840555097287593\n",
            "total= 20609\n",
            "Batch 55 out of  63\n",
            "Accuracy= 0.17368796010448825\n",
            "Top5Accuaracy= 0.3153645214913322\n",
            "Top10Accuaracy= 0.3845642365233911\n",
            "total= 21055\n",
            "Batch 56 out of  63\n",
            "Accuracy= 0.17348180031814353\n",
            "Top5Accuaracy= 0.31458781697389354\n",
            "Top10Accuaracy= 0.3841115373818658\n",
            "total= 21374\n",
            "Batch 57 out of  63\n",
            "Accuracy= 0.1745151084414691\n",
            "Top5Accuaracy= 0.31564950249896834\n",
            "Top10Accuaracy= 0.38502453115686186\n",
            "total= 21809\n",
            "Batch 58 out of  63\n",
            "Accuracy= 0.17440912795436023\n",
            "Top5Accuaracy= 0.31549397808566515\n",
            "Top10Accuaracy= 0.3845422439554469\n",
            "total= 22086\n",
            "Batch 59 out of  63\n",
            "Accuracy= 0.17401058960782553\n",
            "Top5Accuaracy= 0.3148613479314368\n",
            "Top10Accuaracy= 0.3840527685542493\n",
            "total= 22286\n",
            "Batch 60 out of  63\n",
            "Accuracy= 0.1736364035280179\n",
            "Top5Accuaracy= 0.31423054982667076\n",
            "Top10Accuaracy= 0.3835183641230418\n",
            "total= 22789\n",
            "Batch 61 out of  63\n",
            "Accuracy= 0.17359434287685407\n",
            "Top5Accuaracy= 0.3140738185581235\n",
            "Top10Accuaracy= 0.38379613659882716\n",
            "total= 23192\n",
            "Batch 62 out of  63\n",
            "Accuracy= 0.1738064025034888\n",
            "Top5Accuaracy= 0.3147122256523026\n",
            "Top10Accuaracy= 0.3842770753161078\n",
            "total= 23647\n",
            "Batch 63 out of  63\n",
            "Accuracy= 0.1737582712119943\n",
            "Top5Accuaracy= 0.314347935337968\n",
            "Top10Accuaracy= 0.38420303207973866\n",
            "total= 23878\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "auOI8n5gavFM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_pred = model.predict(w2v_X_test.reshape(-1,seq_len,300))\n",
        "test_pred.shape"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}