{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.util import ngrams\n",
    "from collections import defaultdict\n",
    "from collections import OrderedDict\n",
    "import string\n",
    "import time\n",
    "import gc\n",
    "from math import log10\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "emails_tokens=pd.read_pickle('./emailTokens')\n",
    "emails=pd.DataFrame(emails_tokens)\n",
    "df=emails\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=emails[0:258700]\n",
    "test = emails[336310:]\n",
    "valid=emails[258700:336310]\n",
    "test.to_csv('testing_set_2.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def loadCorpus(df, bi_dict, tri_dict, quad_dict, vocab_dict):\n",
    "\n",
    "    w1 = ''    #for storing the 3rd last word to be used for next token set\n",
    "    w2 = ''    #for storing the 2nd last word to be used for next token set\n",
    "    w3 = ''    #for storing the last word to be used for next token set\n",
    "    token = []\n",
    "    word_len = 0\n",
    "    for token in df['message_tokens']:\n",
    "\n",
    "        word_len = word_len + len(token)  \n",
    "        if not token:\n",
    "            continue\n",
    "        if w3!= '':\n",
    "            token.insert(0,w3)\n",
    "\n",
    "        temp0 = list(ngrams(token,2))\n",
    "        if w2!= '':\n",
    "            token.insert(0,w2)\n",
    "        temp1 = list(ngrams(token,3))\n",
    "        if w1!= '':\n",
    "            token.insert(0,w1)\n",
    "        for word in token:\n",
    "            if word not in vocab_dict:\n",
    "                vocab_dict[word] = 1\n",
    "            else:\n",
    "                vocab_dict[word]+= 1\n",
    "        temp2 = list(ngrams(token,4))\n",
    "        for t in temp0:\n",
    "            sen = ' '.join(t)\n",
    "            bi_dict[sen] += 1\n",
    "        for t in temp1:\n",
    "            sen = ' '.join(t)\n",
    "            tri_dict[sen] += 1\n",
    "        for t in temp2:\n",
    "            sen = ' '.join(t)\n",
    "            quad_dict[sen] += 1\n",
    "        n = len(token)\n",
    "        if (n -3) >= 0:\n",
    "            w1 = token[n -3]\n",
    "        if (n -2) >= 0:\n",
    "            w2 = token[n -2]\n",
    "        if (n -1) >= 0:\n",
    "            w3 = token[n -1]\n",
    "    return word_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def findQuadgramProbAdd1(vocab_dict, bi_dict, tri_dict, quad_dict, quad_prob_dict):\n",
    "    i = 0\n",
    "    V = len(vocab_dict)\n",
    "    for quad_sen in quad_dict:\n",
    "        quad_token = quad_sen.split()\n",
    "        tri_sen = ' '.join(quad_token[:3])\n",
    "        prob = ( quad_dict[quad_sen] + 1 ) / ( tri_dict[tri_sen] + V)\n",
    "        if tri_sen not in quad_prob_dict:\n",
    "            quad_prob_dict[tri_sen] = []\n",
    "            quad_prob_dict[tri_sen].append([prob,quad_token[-1]])\n",
    "        else:\n",
    "            quad_prob_dict[tri_sen].append([prob,quad_token[-1]])\n",
    "    prob = None\n",
    "    quad_token = None\n",
    "    tri_sen = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findTrigramProbAdd1(vocab_dict, bi_dict, tri_dict, tri_prob_dict):\n",
    "    V = len(vocab_dict)\n",
    "    for tri in tri_dict:\n",
    "        tri_token = tri.split()\n",
    "        bi_sen = ' '.join(tri_token[:2])\n",
    "        prob = ( tri_dict[tri] + 1 ) / ( bi_dict[bi_sen] + V)\n",
    "        if bi_sen not in tri_prob_dict:\n",
    "            tri_prob_dict[bi_sen] = []\n",
    "            tri_prob_dict[bi_sen].append([prob,tri_token[-1]])\n",
    "        else:\n",
    "            tri_prob_dict[bi_sen].append([prob,tri_token[-1]])\n",
    "    prob = None\n",
    "    tri_token = None\n",
    "    bi_sen = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findBigramProbAdd1(vocab_dict, bi_dict, bi_prob_dict):\n",
    "    V = len(vocab_dict)\n",
    "    for bi in bi_dict:\n",
    "        bi_token = bi.split()\n",
    "        unigram = bi_token[0]\n",
    "        prob = ( bi_dict[bi] + 1 ) / ( vocab_dict[unigram] + V)\n",
    "        if unigram not in bi_prob_dict:\n",
    "            bi_prob_dict[unigram] = []\n",
    "            bi_prob_dict[unigram].append([prob,bi_token[-1]])\n",
    "        else:\n",
    "            bi_prob_dict[unigram].append([prob,bi_token[-1]])\n",
    "    prob = None\n",
    "    bi_token = None\n",
    "    unigram = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimateParameters(valid,token_len, vocab_dict, bi_dict, tri_dict, quad_dict):\n",
    "    max_prob = -9999999999999999999.0\n",
    "    curr_prob = 0.0\n",
    "    parameters = [0.0,0.0,0.0,0.0]\n",
    "    i = 1\n",
    "    held_out_data = valid['message_tokens']\n",
    "    for quad in held_out_data:\n",
    "        quad_token_heldout = list(ngrams(quad,4))\n",
    "        l1 = 0\n",
    "        l4 = 0\n",
    "        while l1 <= 1.0:\n",
    "            l2 = 0\n",
    "            while l2 <= 1.0:\n",
    "                l3 = 0\n",
    "                while l3 <= 1.0:\n",
    "                    if l1 == 0 and l2 == 0 and l3 == 0 or ((l1+l2+l3)>1):\n",
    "                        l3 += 0.1\n",
    "                        i += 1\n",
    "                        continue\n",
    "                    l4 = 1- (l1 + l2 + l3)      \n",
    "                    curr_prob = 0\n",
    "                    qc = [0]\n",
    "                    bc = [0]\n",
    "                    tc = [0]\n",
    "                    for quad in quad_token_heldout:\n",
    "                        curr_prob += log10( interpolatedProbability(quad,token_len, vocab_dict, bi_dict, tri_dict, \n",
    "                                                                    quad_dict,qc,bc,tc,l1, l2, l3, l4) )\n",
    "                    if curr_prob > max_prob:\n",
    "                        max_prob = curr_prob\n",
    "                        parameters[0] = l1\n",
    "                        parameters[1] = l2\n",
    "                        parameters[2] = l3\n",
    "                        parameters[3] = l4\n",
    "                    l3 += 0.1\n",
    "                    i += 1\n",
    "\n",
    "                l2 += 0.1\n",
    "            l1 += 0.1\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolatedProbability(quad_token,token_len, vocab_dict, bi_dict, tri_dict, quad_dict, qc, tc, bc,\n",
    "                            l1 = 0.25, l2 = 0.25, l3 = 0.25 , l4 = 0.25):\n",
    "    V = len(vocab_dict)\n",
    "    \n",
    "    sen = ' '.join(quad_token)\n",
    "    prob = (   \n",
    "              l1*((quad_dict[sen] + 1)/ (tri_dict[' '.join(quad_token[0:3])] + V)) \n",
    "            + l2*((tri_dict[' '.join(quad_token[1:4])] + 1) / (bi_dict[' '.join(quad_token[1:3])] + V)) \n",
    "            + l3*((bi_dict[' '.join(quad_token[2:4])] + 1) / (vocab_dict[quad_token[2]] + V)) \n",
    "            + l4*((vocab_dict[quad_token[3]] + 1) / (token_len + V))\n",
    "           )\n",
    "    \n",
    "    if sen  in quad_dict:\n",
    "        qc[0] += 1\n",
    "    if ' '.join(quad_token[1:4]) in tri_dict:\n",
    "        tc[0] += 1\n",
    "    if ' '.join(quad_token[2:4])  in bi_dict:\n",
    "        bc[0] += 1    \n",
    "    if prob <= 0:\n",
    "        return 1\n",
    "    \n",
    "    return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def sortProbWordDict(bi_prob_dict, tri_prob_dict, quad_prob_dict):\n",
    "    #sort bigram dict\n",
    "    for key in bi_prob_dict:\n",
    "        if len(bi_prob_dict[key])>1:\n",
    "            bi_prob_dict[key] = sorted(bi_prob_dict[key],reverse = True)\n",
    "    \n",
    "    #sort trigram dict\n",
    "    for key in tri_prob_dict:\n",
    "        if len(tri_prob_dict[key])>1:\n",
    "            tri_prob_dict[key] = sorted(tri_prob_dict[key],reverse = True)\n",
    "    \n",
    "    #sort quadgram dict\n",
    "    for key in quad_prob_dict:\n",
    "        if len(quad_prob_dict[key])>1:\n",
    "            quad_prob_dict[key] = sorted(quad_prob_dict[key],reverse = True)[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def chooseWords(sen, bi_prob_dict, tri_prob_dict, quad_prob_dict):\n",
    "    word_choice = []\n",
    "    token = sen.split()\n",
    "    if token[-1] in bi_prob_dict:\n",
    "        word_choice +=  bi_prob_dict[token[-1]][:1]\n",
    "        #print('Word Choice bi dict')\n",
    "    if ' '.join(token[1:]) in tri_prob_dict:\n",
    "        word_choice +=  tri_prob_dict[' '.join(token[1:])][:1]\n",
    "        #print('Word Choice tri_dict')\n",
    "    if ' '.join(token) in quad_prob_dict:\n",
    "        word_choice += quad_prob_dict[' '.join(token)][:1]\n",
    "        #print('Word Choice quad_dict')\n",
    "    \n",
    "    return word_choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def doInterpolatedPredictionAdd1(sen, bi_dict, tri_dict, quad_dict, \n",
    "                             vocab_dict,token_len, word_choice, param):\n",
    "    pred = ''\n",
    "    max_prob = 0.0\n",
    "#     V = len(vocab_dict)\n",
    "    V=67007\n",
    "    #for each word choice find the interpolated probability and decide\n",
    "    for word in word_choice:\n",
    "        key = sen + ' ' + word[1]\n",
    "        quad_token = key.split()\n",
    "        \n",
    "        prob = (   \n",
    "                  param[0]*((quad_dict[key] + 1)/ (tri_dict[' '.join(quad_token[0:3])] + V)) \n",
    "                + param[1]*((tri_dict[' '.join(quad_token[1:4])] + 1) / (bi_dict[' '.join(quad_token[1:3])] + V)) \n",
    "                + param[2]*((bi_dict[' '.join(quad_token[2:4])] + 1) / (vocab_dict[quad_token[2]] + V)) \n",
    "                + param[3]*((vocab_dict[quad_token[3]] + 1) / (token_len + V))\n",
    "               )\n",
    "        \n",
    "        if prob > max_prob:\n",
    "            max_prob = prob\n",
    "            pred = word\n",
    "    #return only pred to get word with its prob\n",
    "    if pred:\n",
    "        return pred[1]\n",
    "    else:\n",
    "        return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def computeTestScore(test_token,bi_dict, tri_dict, quad_dict, vocab_dict,\n",
    "                     bi_prob_dict, tri_prob_dict, quad_prob_dict, token_len,param):\n",
    "    \n",
    "    \n",
    "    #increment the score value if correct prediction is made else decrement its value\n",
    "    score = 0\n",
    "    wrong = 0\n",
    "    total = 0\n",
    "    for tokens in test_token:\n",
    "        for sent in tokens:\n",
    "            if(len(sent)<4):\n",
    "                break\n",
    "            sen_token = sent[:3]\n",
    "            sen = \" \".join(sen_token)\n",
    "            correct_word = sent[3]\n",
    "            word_choice = chooseWords(sen, bi_prob_dict, tri_prob_dict, quad_prob_dict)\n",
    "            result = doInterpolatedPredictionAdd1(sen, bi_dict, tri_dict, quad_dict, vocab_dict,token_len, word_choice, param)\n",
    "\n",
    "            if result == correct_word:\n",
    "                score+=1\n",
    "            else:\n",
    "                wrong += 1\n",
    "\n",
    "            total += 1\n",
    "\n",
    "    print('Total Word Predictions: '+str(total) + '\\n' +'Correct Predictions: '+str(score) +\n",
    "                    '\\n'+'Wrong Predictions: '+str(wrong) + '\\n'+'acc:'+str((score/total)*100) )\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def computePerplexity(test_quadgrams,token_len,tri_dict,quad_dict,vocab_dict,prob_dict):\n",
    "    \n",
    "    perplexity = float(1.0)\n",
    "    n = token_len\n",
    "#     V = len(vocab_dict)\n",
    "    V=67007\n",
    "    for item in quad_dict:\n",
    "        sen_token = item.split()\n",
    "        tri_sen = ' '.join(sen_token[0:3])\n",
    "        prob = (quad_dict[item] + 1) / (tri_dict[tri_sen] + V)\n",
    "        perplexity = perplexity * ( prob**(1./n))\n",
    "    with open('Test_Scores/add1_smoothing_score.txt','w') as w:\n",
    "        w.write('\\nPerplexity: '+str(perplexity))\n",
    "    return perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def trainCorpus(valid,train_file,test_file,bi_dict,tri_dict,quad_dict,vocab_dict,prob_dict):\n",
    "    score = 0\n",
    "    \n",
    "    #load the training corpus for the dataset\n",
    "    token_len = loadCorpus(train_file, bi_dict, tri_dict, quad_dict, vocab_dict)\n",
    "    print(\"---Processing Time for Corpus Loading: %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "    start_time1 = time.time()\n",
    "\n",
    "    param = estimateParameters(valid,token_len, vocab_dict, bi_dict, tri_dict, quad_dict)    \n",
    "    #create trigram Probability Dictionary\n",
    "    findTrigramProbAdd1(vocab_dict, bi_dict, tri_dict, tri_prob_dict)\n",
    "    #create bigram Probability Dictionary\n",
    "    findBigramProbAdd1(vocab_dict, bi_dict, bi_prob_dict)\n",
    "    #create quadgram Probability Dictionary\n",
    "    findQuadgramProbAdd1(vocab_dict, bi_dict, tri_dict, quad_dict, quad_prob_dict)\n",
    "    #sort the probability dictionaries\n",
    "    sortProbWordDict(bi_prob_dict, tri_prob_dict, quad_prob_dict)\n",
    "    gc.collect()\n",
    "    print(\"Preprocessing Time for Creating Probable Word Dict: %s seconds\" % (time.time() - start_time1))\n",
    "\n",
    "    test_quadgrams = list(ngrams(test['message_tokens'],4))\n",
    "    start_time2 = time.time()\n",
    "    score = computeTestScore(test_quadgrams,bi_dict, tri_dict, quad_dict, vocab_dict,\n",
    "                     bi_prob_dict, tri_prob_dict, quad_prob_dict, token_len,param)\n",
    "    print('Score:',score)\n",
    "    print(\"Processing Time for computing score: %s seconds\" % (time.time() - start_time2))\n",
    "\n",
    "    start_time3 = time.time()\n",
    "    perplexity = computePerplexity(test_quadgrams,token_len,tri_dict,quad_dict,vocab_dict,prob_dict)\n",
    "    print('Perplexity:',perplexity)\n",
    "    print(\"Processing Time for computing Perplexity: %s seconds\" % (time.time() - start_time3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_file = 'train.csv'\n",
    "test_file = 'test.csv'\n",
    "token_len = trainCorpus(valid,df,test_file,bi_dict,tri_dict,quad_dict,vocab_dict,quad_prob_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Testing the Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "test = pd.read_csv('testing_set_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_dict = defaultdict(int)          \n",
    "bi_dict = defaultdict(int)             \n",
    "tri_dict = defaultdict(int)            \n",
    "quad_dict = defaultdict(int)           \n",
    "quad_prob_dict = defaultdict(list)             \n",
    "tri_prob_dict = defaultdict(list)              \n",
    "bi_prob_dict = defaultdict(list)              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_quadgrams = list(ngrams(test['message_tokens'],4))\n",
    "import numpy as np\n",
    "bi_dict=np.load(\"bi_dict.npy\")  \n",
    "tri_dict = np.load(\"tri_dict.npy\")\n",
    "quad_dict = np.load(\"quad_dict.npy\")\n",
    "vocab_dict=np.load(\"vocab_dict.npy\")\n",
    "bi_prob_dict=np.load(\"bi_prob_dict.npy\")\n",
    "tri_prob_dict=np.load(\"tri_prob_dict.npy\")\n",
    "quad_prob_dict=np.load(\"quad_prob_dict.npy\")\n",
    "token_len=64355494\n",
    "#choose most probable words for prediction\n",
    "start_time2 = time.time()\n",
    "param=[0,0,0.1,0.9]\n",
    "score = computeTestScore(test_quadgrams,bi_dict, tri_dict, quad_dict, vocab_dict,\n",
    "                 bi_prob_dict, tri_prob_dict, quad_prob_dict, token_len,param)\n",
    "print('Score:',score)\n",
    "print(\"Processing Time for computing score: %s seconds\" % (time.time() - start_time2))\n",
    "\n",
    "start_time3 = time.time()\n",
    "perplexity = computePerplexity(test_quadgrams,token_len,tri_dict,quad_dict,vocab_dict,prob_dict)\n",
    "print('Perplexity:',perplexity)\n",
    "print(\"Processing Time for computing Perplexity: %s seconds\" % (time.time() - start_time3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
